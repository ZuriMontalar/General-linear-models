---
title: "Tarea 2 GLM"
author: "Zuri Montalar"
output: pdf_document
editor_options: 
  chunk_output_type: console
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=TRUE,echo=FALSE,warning=FALSE, error=FALSE)
```


```{r include=FALSE}
setwd("~/BIOESTADÍSTICA máster/IV. Modelización avanzada/Modelo lineales generalizados/Tareas GLM/tarea 2 GLM")
library(faraway)
library(AER)
library(DHARMa)
library(MASS)
library(ResourceSelection)
library(pROC)
library(boot)
library(glmulti)
```

```{r}
## cargar datos
datos<-read.csv("quejas.dat",sep="")
```


Disponemos de 44 observaciones de datos sobre el número de quejas a médicos de un servicio de urgencias en un hospital, y pretendemos encontrar un modelo que explique el efecto que tienen sobre las mismas el resto de variables analizadas. Entonces, la variable respuesta es el número de quejas a los médicos por lo que es cuantitativa discreta. Las variables explicativas son las siguientes: la cantidad de consultas que ha realizado el médico, tratándose entonces de una variable cuantitativa discreta; si el médico ha sido residente o no en un servicio de urgencias, siendo una variable categórica binaria, con valores "sí" o "no"; el sexo del médico, siendo también categórica binaria, pero con valores de "hombre" o "mujer"; sus ingresos, que es una variable cuantitativa continua; y el número de horas de servicio en el turno de guardia, también un cuantitativa continua.


En la siguiente tabla vemos los estadísticos básicos de las variables *ingresos*, *horas* y *consultas* (pese a ser esta última discreta, por tomar una gran cantidad de posibles valores).

```{r results="markup"}
## descriptiva
summary(datos[,c(1,5,6)])
```

También podemos visualizar los histogramas de esas variables:

```{r results="markup",fig.align="center",warning=FALSE, error=FALSE,fig.width=12,fig.height=4}
par(mfrow=c(1,3))
hist(datos$consultas)
hist(datos$ingresos)
hist(datos$horas)
par(mfrow=c(1,1))
```

En las dos siguientes tablas vemos la cantidad de quejas que se han puesto a los médicos según si son o no residentes y según el sexo; y representamos a continuación esos datos con diagramas de barras:

```{r results="markup",fig.align="center",warning=FALSE, error=FALSE,fig.width=12,fig.height=4}
table(datos[,c(3,2)])
table(datos[,c(4,2)])
par(mfrow=c(1,2))
barplot(table(datos[,c(3,2)]),xlab="nº quejas",col=2:3,ylab="nº médicos",beside=TRUE,main="Datos quejas según residente o no")
legend("topright",col=2:3,pch=15,cex=0.85,
      legend=c("No residente","Residente"))
barplot(table(datos[,c(4,2)]),xlab="nº quejas",col=4:5,ylab="nº médicos",beside=TRUE,main="Datos quejas según sexo")
legend("topright",col=4:5,pch=15,cex=0.85,
      legend=c("Hombre","Mujer"))
par(mfrow=c(1,1))
```

También podemos observar gráficamente cuál es la relación de las variables entre ellas:

```{r results="markup",warning=FALSE, error=FALSE,fig.width=5,fig.height=5,fig.align="center"}
pairs(datos)
```

Como la variable respuesta son conteos, sigue una distribución Poisson, por lo que tenemos que $quejas_i~(i=1,...,44) i.i.d\sim Po(\mu_i)$, con $E(quejas_i)=Var(quejas_i)=\mu_i$, siendo $\mu$ el parámetro de interés, es decir, el número medio de quejas.



Realizaremos en principio entonces una regresión de Poisson. Sin embargo, si se da sobredispersión, nos plantearemos más bien una distribución binomial negativa. En estos casos, lo más habitual es utilizar el link log para relacionar el predictor lineal con la respuesta media.


```{r results="hide"}
## modelo1 con todas las variables
modelo1<-glm(quejas~ .,family=poisson(link="log"),datos)
# summary(modelo1)
# par(mfrow=c(2,2)); plot(modelo1); par(mfrow=c(1,1))
1-pchisq(modelo1$deviance,df=modelo1$df.residual)
1-(modelo1$deviance/modelo1$null.deviance) # Proporción de deviance explicada
# Aplicabilidad
res.modelo1<-residuals(modelo1,type ="deviance")
shapiro.test(res.modelo1); ks.test(res.modelo1,"pnorm")
sum(abs(res.modelo1)>2)*100
```

Empezamos entonces proponiendo un modelo lineal generalizado que incluye todas las variables disponibles (lo llamamos en este caso *modelo1*), utilizando el link log. Tenemos que la única variable significativa es *consultas* y hemos obtenido un AIC de 184.77.

Además todos los residuos deviance están entre -2 y 2, y al realizar sobre los mismos los tests de normalidad Shapiro y Kolmogorov-Smirnov tenemos, respectivamente, p-valores de 0.05187 y 0.1245, por lo que, con un nivel de significatividad del 5% (que es el que utilizaremos a lo largo de todo el trabajo), no tenemos evidencia estadística suficiente para rechazar la hipótesis nula y aceptamos entonces que los residuos son normales.

Para saber si el modelo es bueno, utilizamos el estadístico Deviance, que compara nuestro modelo con uno saturado, de modo que tenemos un buen ajuste si la Deviance se distribuye como una $\chi^2$ con $n-p+1$ (38 en nuestro caso) grados de libertad. Hemos obtenido un p-valor de 0.092, por lo que aceptamos que es un buen ajuste. Sin embargo, también hemos obtenido una proporción de deviance explicada ($D^2$) de 0.441, la cual nos interesa que sea cercana a 1 y por tanto pensamos que podríamos conseguir un modelo más adecuado que este.

```{r results="hide"}
dispersiontest(modelo1)
# plot(log(fitted(modelo1)),log((datos$quejas-fitted(modelo1))^2),
#      xlab=expression(hat(mu)),ylab=expression((y-hat(mu))^2),
#      xlim = c(-5,10), ylim = c(-5,10))
# abline(0,1)
sim_modelo1<- simulateResiduals(modelo1,refit=T) 
testDispersion(sim_modelo1,plot=FALSE)
# plot(sim_modelo1)
```

Por otro lado, debemos tener en cuenta al trabajar con una distribución Poisson, la media y la varianza han de ser similares, porque de no ser así podríamos tener algún problema de infradispersión o sobredispersión (siendo esta segunda más común), por lo que estudiamos si tenemos equidispersión. Utilizamos para ello la función `dispersiontest()` del paquete *AER*, y obtenemos un p-valor de 0.2442 y, al ser mayor que 0.05, no tenemos evidencia estadística suficiente para rechazar la hipótesis nula y aceptamos por tanto que tenemos equidispersión. También podemos recurrir a la función `testDispersion()` del paquete *DHARMa*, que realiza un test basado en simulación para la infra o sobredispersión, y con un p-valor de 0.144 llegamos a la misma conclusión de que tenemos equidispersión. Por tanto, seguiremos trabajando con la distribución Poisson.


Con la finalidad de mejorar el modelo, nos planteamos el recurrir a transformaciones o interacciones entre las covariables. Tras varias pruebas, vemos que reducimos el AIC utilizando como fórmula de un nuevo modelo (que llamamos *modelo2*) la siguiente: $quejas\sim (horas+consultas+residente+ingresos)*sexo$. En este caso, el AIC es de 182.91, una $D^2$ de 0.2169 (menor que antes, lo cual no nos interesa), y un p-valor al comparar la Deviance con una $\chi^2$ de 0.55.

```{r results="hide"}
## modelo2 con interacciones
modelo2<-glm(quejas~ (horas+consultas+residente+ingresos)*sexo,family=poisson(link="log"),datos)
# summary(modelo2)
modelo2$aic
1-pchisq(modelo2$deviance,df=modelo2$df.residual)
1-(modelo2$deviance/modelo2$null.deviance)
```


Estudiamos la posible sobredispersión del *modelo2*. Con la función `dispersiontest()` obtenemos un p-valor de 0.7713, y con la función `testDispersion()` tenemos un p-valor de 0.416, por lo que no tenemos evidencia estadística suficiente para rechazar las hipótesis nulas y aceptamos que tenemos equidispersión.

```{r results="hide"}
dispersiontest(modelo2)
# plot(log(fitted(modelo2)),log((datos$quejas-fitted(modelo2))^2),
#      xlab=expression(hat(mu)),ylab=expression((y-hat(mu))^2),
#      xlim = c(-5,10), ylim = c(-5,10))
# abline(0,1)
sim_modelo2<- simulateResiduals(modelo2,refit=T) 
testDispersion(sim_modelo2,plot=FALSE)
```



```{r results="hide"}
## selección variables con step()
aj.step<-step(modelo2,trace=FALSE)
# summary(aj.step)
1-pchisq(aj.step$deviance,df=aj.step$df.residual)
1-(aj.step$deviance/aj.step$null.deviance)
```

A continuación, utilizamos la función `step()` del paquete *stats* partiendo del *modelo2* para seleccionar un modelo más adecuado en términos de AIC. Sin embargo, al hacerlo obtenemos el mismo modelo, el cual no nos convence por la gran cantidad de coeficientes no significativos que presenta.


```{r results="hide"}
## modelo3 usando glmulti()
mod.multi<-glmulti(quejas~.,data=datos,family=poisson(link="log"),crit=aic,level=2,plotty=FALSE,report=FALSE)
mod.multi@formulas[[1]]
modelo3<-glm(quejas~1+residente+consultas+residente:consultas,family=poisson(link="log"),datos)
# summary(modelo3)
modelo3$aic
1-pchisq(modelo3$deviance,df=modelo3$df.residual)
1-(modelo3$deviance/modelo3$null.deviance)
```

Decidimos entonces recurrir al la función `glmulti()` del paquete del mismo nombre para buscar, también con el criterio del menor AIC, el mejor modelo, pero esta vez indicando que realice la búsqueda hasta interacciones de dos en dos entre variables. Tenemos entonces un *modelo3* cuya fórmula es $quejas\sim1+residente+consultas+residente:consultas$, con AIC 177.29,  una $D^2$ de 0.222 (similar al del *modelo2*), y un p-valor al comparar la Deviance con una $\chi^2$ de 0.48, de modo que parece un buen ajuste. Sin embargo el *modelo3* únicamente depende de las variables *residente* y *consultas*, de modo que nos daría a entender que la cantidad de quejas a los médicos no depende del resto de variables como *sexo*, *ingresos* u *horas*. 


Como no sabemos cuál de los tres modelos propuestos predice mejor, utilizamos un método basado en validación cruzada mediante la función `cv.glm()` del paquete *boot*.

```{r results="hide"}
## validación cruzada
set.seed (1)
cv10<-matrix(nrow=100,ncol=3)
for(i in 1:100){
cv10[i,]<-c(cv.glm(datos,modelo1,K=10)$delta[2],
            cv.glm(datos,modelo2,K=10)$delta[2],
            cv.glm(datos,modelo3,K=10)$delta[2])}
apply(cv10,2,mean)
```

La primera componente de $\delta$ tras la validación cruzada son los estimadores $\hat{\sigma}^2$ (la varianza residual), pero esa estimación está sesgada, por lo que comparamos la segunda componente de $\delta$, que corrige dicho sesgo. Sin embargo, esos valores son muy similares, y por la aleatoriedad intrínseca en este método, según la semilla que utilicemos obtenemos $\delta$'s de unos modelos mejores (menores) que de otros. Por ello, aleatorizamos el proceso de selección de grupos, realizando varias veces (100) la validación cruzada, y mostrando la media de todas las iteraciones para cada ajuste (aunque también depende de la cantidad de grupos escogidos, que en este caso fijamos a 10). Entonces, supondremos que el modelo que mejor predice es el que tenga menor (media de) varianza residual corregida, que en este caso son 5.143, 9.319 y 5.187 para los modelos *modelo1*, *modelo2* y *modelo3*, respectivamente. Con ello, mediante validación cruzada deducimos que predecimos peor con el *modelo2*, y de forma similar con los modelos *modelo1* y *modelo3*.

Sin embargo pese a haber obtenido una (media de) varianza residual corregida un poco mayor en el *modelo3* que en el *modelo1* (y por tanto predeciríamos peor), hay que tener en cuenta que el AIC del *modelo3* era menor que el del *modelo1*, además de presentar una diferencia más significativa con el modelo saturado. Con ello, elegimos como modelo final el *modelo3*, que mostramos a continuación:


```{r fig.width=5,fig.height=5,fig.align="center"}
## modelo final
summary(modelo3)
par(mfrow=c(2,2)); plot(modelo3); par(mfrow=c(1,1))
```

Estudiamos la aplicabilidad del modelo final.

```{r results="markup"}
## Aplicabilidad
res.modelo3<-residuals(modelo3,type ="deviance")
shapiro.test(res.modelo3); ks.test(res.modelo3,"pnorm")
```

En las gráficas anteriores vemos que todos los residuos deviance están entre -2 y 2, y al realizar sobre los mismos los tests de normalidad Shapiro y Kolmogorov-Smirnov tenemos, respectivamente, p-valores de 0.075 y 0.148, por lo que no tenemos evidencia estadística suficiente para rechazar las hipótesis nulas y aceptamos entonces que los residuos son normales. Esto también lo podemos apreciar en el gráfico *Normal Q-Q*.

Entonces, finalmente tenemos, $$log(mu_i)=-1.6322+1.2747\cdot residente+0.0011\cdot consultas-0.0006\cdot residente\cdot consultas $$
$residente$ toma el valor "0" si el médico no ha sido residente, y "1" si sí lo ha sido.


Como hemos aplicado el link log, tenemos que nuestra variable de interés, la media de las quejas, es la siguiente:
$$
\mu_i=e^{-1.6322+1.2747\cdot residente+0.0011\cdot consultas-0.0006\cdot residente\cdot consultas}
$$

Por tanto, según el modelo final, el sexo del médico no influye en que este reciba más o menos quejas, ni las horas de servicio del turno de guardia, ni sus ingresos. La variables que sí influyen en el número medio de quejas recibidas son, de entre las que tenemos datos, el número de consultas que ha realizado el médico, así como si éste ha sido o no residente.

El coeficiente positivo (y también más elevado) de $residente$ indica que los médicos residentes reciben más quejas que los no residentes. También reciben más quejas los médicos que más consultas han realizado. Sin embargo, el coeficiente negativo de $residente\cdot consultas$ nos lleva a pensar que si son residentes, reciben menos quejas al realizar más consultas que si no fueran residentes, aunque también es cierto que ese coeficiente es bastante cercano a 0. Esto mismo lo podemos apreciar también si hacemos predicciones con nuestro modelo: en la siguiente tabla, vemos predicciones de las quejas medias para médicos no residentes en la primera fila y médicos residentes en la segunda; y las columnas corresponden, por orden, a 1000, 2000 y 3000 consultas realizadas por los médicos.

```{r results="markup"}
C<-c(1000,2000,3000)
R<-c(0,1)
predicciones<-matrix(ncol=length(C),nrow=length(R))
for (i in 1:length(R)) for (j in 1:length(C)) {
  predicciones[i,j]<-exp(sum(modelo3$coefficients*c(1,R[i],C[j],C[j]*R[i])))
}
predicciones
```


## Anexo: Código de R

<!-- ```{r ref.label=knitr::all_labels(),echo=TRUE,eval=FALSE} -->

<!-- ``` -->


<!-- ```{r code=readLines(knitr::purl('~/path/to/file.Rmd', documentation = 0)), eval = FALSE} -->

<!-- ``` -->


```{r message=F,results="hide",error=FALSE,echo=TRUE,eval=FALSE}
## cargar datos
datos<-read.csv("quejas.dat",sep="")

## descriptiva
summary(datos[,c(1,5,6)])
par(mfrow=c(1,3))
hist(datos$consultas)
hist(datos$ingresos)
hist(datos$horas)
par(mfrow=c(1,1))
table(datos[,c(3,2)])
table(datos[,c(4,2)])
par(mfrow=c(1,2))
barplot(table(datos[,c(3,2)]),xlab="nº quejas",col=2:3,ylab="nº médicos",
        beside=TRUE,main="Datos quejas según residente o no")
legend("topright",col=2:3,pch=15,cex=0.85,
      legend=c("No residente","Residente"))
barplot(table(datos[,c(4,2)]),xlab="nº quejas",col=4:5,ylab="nº médicos",
        beside=TRUE,main="Datos quejas según sexo")
legend("topright",col=4:5,pch=15,cex=0.85,
      legend=c("Hombre","Mujer"))
par(mfrow=c(1,1))
pairs(datos)

## modelo1 con todas las variables
modelo1<-glm(quejas~ .,family=poisson(link="log"),datos)
# summary(modelo1)
# par(mfrow=c(2,2)); plot(modelo1); par(mfrow=c(1,1))
1-pchisq(modelo1$deviance,df=modelo1$df.residual)
1-(modelo1$deviance/modelo1$null.deviance) # Proporción de deviance explicada
# Aplicabilidad
res.modelo1<-residuals(modelo1,type ="deviance")
shapiro.test(res.modelo1); ks.test(res.modelo1,"pnorm")
sum(abs(res.modelo1)>2)*100
dispersiontest(modelo1)
# plot(log(fitted(modelo1)),log((datos$quejas-fitted(modelo1))^2),
#      xlab=expression(hat(mu)),ylab=expression((y-hat(mu))^2),
#      xlim = c(-5,10), ylim = c(-5,10))
# abline(0,1)
sim_modelo1<- simulateResiduals(modelo1,refit=T)
testDispersion(sim_modelo1,plot=FALSE)
# plot(sim_modelo1)

## modelo2 con interacciones
modelo2<-glm(quejas~ (horas+consultas+residente+ingresos)*sexo,
             family=poisson(link="log"),datos)
# summary(modelo2)
modelo2$aic
1-pchisq(modelo2$deviance,df=modelo2$df.residual)
1-(modelo2$deviance/modelo2$null.deviance)
dispersiontest(modelo2)
# plot(log(fitted(modelo2)),log((datos$quejas-fitted(modelo2))^2),
#      xlab=expression(hat(mu)),ylab=expression((y-hat(mu))^2),
#      xlim = c(-5,10), ylim = c(-5,10))
# abline(0,1)
sim_modelo2<- simulateResiduals(modelo2,refit=T)
testDispersion(sim_modelo2,plot=FALSE)
## selección variables con step()
aj.step<-step(modelo2,trace=FALSE)
# summary(aj.step)
1-pchisq(aj.step$deviance,df=aj.step$df.residual)
1-(aj.step$deviance/aj.step$null.deviance)

## modelo3 usando glmulti()
mod.multi<-glmulti(quejas~.,data=datos,family=poisson(link="log"),
                   crit=aic,level=2,plotty=FALSE,report=FALSE)
mod.multi@formulas[[1]]
modelo3<-glm(quejas~1+residente+consultas+residente:consultas,
             family=poisson(link="log"),datos)
# summary(modelo3)
modelo3$aic
1-pchisq(modelo3$deviance,df=modelo3$df.residual)
1-(modelo3$deviance/modelo3$null.deviance)

## validación cruzada
set.seed (1)
cv10<-matrix(nrow=100,ncol=3)
for(i in 1:100){
cv10[i,]<-c(cv.glm(datos,modelo1,K=10)$delta[2],
            cv.glm(datos,modelo2,K=10)$delta[2],
            cv.glm(datos,modelo3,K=10)$delta[2])}
apply(cv10,2,mean)

## modelo final
summary(modelo3)
par(mfrow=c(2,2)); plot(modelo3); par(mfrow=c(1,1))
# aplicabilidad
res.modelo3<-residuals(modelo3,type ="deviance")
shapiro.test(res.modelo3); ks.test(res.modelo3,"pnorm")
C<-c(1000,2000,3000)
R<-c(0,1)

## predicciones
predicciones<-matrix(ncol=length(C),nrow=length(R))
for (i in 1:length(R)) for (j in 1:length(C)) {
  predicciones[i,j]<-exp(sum(modelo3$coefficients*c(1,R[i],C[j],C[j]*R[i])))
}
predicciones
```

